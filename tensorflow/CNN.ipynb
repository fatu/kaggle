{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN的基本原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 卷积层\n",
    "* 池化层\n",
    "* 全接连层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 通道\n",
    "* 卷积核"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "手动实现卷积层numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x: input\n",
    "# w: kernel\n",
    "# b: bias\n",
    "# pad: padding\n",
    "def conv_numpy(x, w, b, pad, strides):\n",
    "    out = None\n",
    "    \n",
    "    N, H, W, C = x.shape # N:sampls, H: height, W:width, C: Channel\n",
    "    F, HH, WW, C = w.shape # F: output channel, HH: height, WW: width, C: input channel\n",
    "    \n",
    "    X = np.pad(x, ((0, 0), (pad, pad), (pad, pad) (0, 0)), 'constant') #(00pppp00) -> NHWC\n",
    "    \n",
    "    Hn = 1 + int((H + 2 * pad - HH) / strides[0])\n",
    "    Wn = 1 + int((W + 2 * pad - WW) / strides[1])\n",
    "    \n",
    "    out = np.zeros((N, Hn, Wn, F))\n",
    "    \n",
    "    for n in range(N):\n",
    "        for m in range(F):\n",
    "            for i in range(Hn):\n",
    "                for j in range(Wn):\n",
    "                    data = X[n, i * strides[0]:i * strides[0] + HH, j * strides[1]: j * strides[1] + WW, :].reshape(1, -1)\n",
    "                    filt = w[m].reshape(-1, 1)\n",
    "                    out[n, i, j, m] = data.dot(filt) + b[m]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d(x, w, b, pad, stride):\n",
    "    N, H, W, C = tf.shape(x)\n",
    "    F, HH, WW, C = tf.shape(w)\n",
    "    \n",
    "    x = tf.pad(x, ((0,0),(pad, pad),(pad, pad), (0,0)), 'constant')\n",
    "    Hn = 1 + int((H + 2 * pad - HH) / stride[0])\n",
    "    Wn = 1 + int((W + 2 * pad - WW) / stride[1])\n",
    "    Y = tf.Variable(tf.zeros((N, Hn, Wn, F), dtype=tf.float32))\n",
    "    \n",
    "    for m in range(F):\n",
    "        for i in range(Hn):\n",
    "            for j in range(Wn):\n",
    "                data = x[:, i * stride[0]:i * 1 + HH, j * stride[1]:j * 1 + WW, :]\n",
    "                filt = w[m,:,:,:]\n",
    "                Y[:, i, j, m].assign(tf.reduce_sum(tf.multiply(data, filt), axis=(1,2,3))+b[m])\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "手动实现池化层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def max_pool_forward_naive(x, pool_size=(2,2), strides=(1,1)):\n",
    "    \n",
    "    N, H, W, C = x.shape\n",
    "    h_p, w_p = pool_size\n",
    "    h_s, w_s = strides\n",
    "    \n",
    "    Hn = 1 + int((H - h_p) / h_s)\n",
    "    Wn = 1 + int((W - w_p) / w_s)\n",
    "    out = np.zeros((N, Hn, Wn, C))\n",
    "    for i in range(Hn):\n",
    "        for j in range(Wn):\n",
    "            out[:, i, j, :] = np.max(x[:, i*h_s:i*h_s+h_p, j*w_s:j*w_s+w_p,:], axis=(1,2))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool2d(X, pool_size=(2,2), strides=(1,1)):\n",
    "    N, H, W, C = x.shape\n",
    "    h_p, w_p = pool_size\n",
    "    h_s, w_s = strides\n",
    "    Y = tf.zeros((N, (H - p_h + 1)//s_h, (W - p_w + 1)//s_w, C))\n",
    "    Y = tf.Variable(Y)\n",
    "    \n",
    "    for i in tf.range(tf.shape(Y)[1]):\n",
    "        for j in tf.range(tf.shape(Y)[2]):\n",
    "            Y[:,i,j,:].assign(tf.math.reduce_max(X[:,i*s_h:i*s_h+p_h,j*s_w:j*s_w+p_w,:], axis=(1,2),keepdims=False))\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实战 Quick, Draw! Google涂鸦识别比赛"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "评估指标 Mean Average Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apk(actual, predicted, k=10):\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "        \n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "    \n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "    \n",
    "    if not actual:\n",
    "        return 0.0\n",
    "    return score / min(len(actual), k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据shuffle\n",
    "数据的读取方式\n",
    "* 转成TFRecords：会变大，读取速度快\n",
    "* TextLineDataset方式读取CSV文件：**需要对drawing数据进行编码，变成image像素数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Simplified('./data/')\n",
    "NCSVS = 100\n",
    "categories = s.list_all_categories()\n",
    "print(len(categories))\n",
    "\n",
    "for y, cat in tqdm(enumerate(categories)):\n",
    "    df = s.read_training_csv(cat)\n",
    "    df['y'] = y\n",
    "    df['cv'] = (df.key_id // 10 ** 7) % NCSVS\n",
    "    for k in range(NCSVSC):\n",
    "        filename = './shuffle_data/train_k{}.csv'.format(k)\n",
    "        chunk = df[df.cv == k]\n",
    "        chunk = chunk.drop(['key_id'], axis=1)\n",
    "        if y == 0:\n",
    "            chunk.to_csv(filename, index=False)\n",
    "        else:\n",
    "            chunk.to_csv(filename, mode='a', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.io.TFRecordWriter(tfrecord_file) as writer:\n",
    "    for filename in fileList[:1]:\n",
    "        df = pd.read_csv(filename)\n",
    "        df['drawing'] = df['drawing'].apply(json.loads)\n",
    "        for row in range(df.shape[0]):\n",
    "            drawing = df.loc[row, 'drawing']\n",
    "            img = draw_cv2(drawing, BASE_SIZE=128, size=128, lw=6)\n",
    "            img = img.tostring()\n",
    "            label = df.loc[row, 'y']\n",
    "            feature = {\n",
    "                'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=img)),\n",
    "                'label': tf.train.Feature(int64_list=tf.train.Int64List(value=[label]))\n",
    "            }\n",
    "            example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "            writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testline\n",
    "def draw_cs2(raw_strokes, size=64, lw=6):\n",
    "    raw_strokes = eval(raw_strokes.numpy())\n",
    "    img = np.zeros((256, 256), np.uint8)\n",
    "    for stroke in raw_strokes:\n",
    "        for i in range(len(stroke[0] - 1)):\n",
    "            _ = cv2.line(img, (stroke[0][i], stroke[1][i]), (stroke[0][i+1], stroke[1][i+1]), 255, lw)\n",
    "    return cv2.resize(img, (size, size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_draw_cv2(image, label):\n",
    "    [image] = tf.py_function(draw_cv2, [image], [tf.float32]) # 变成了tensor\n",
    "    image = tf.reshape(image, (64,64,1))\n",
    "    label = tf.one_hot(label, depth=NCATS)\n",
    "    image.set_shape((64,64,1))\n",
    "    label.set_shape((340,))\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.TextLineDataset(fileList[2], compression_type='GZIP').skip(1).map(parse_csv, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "train_ds = train_ds.map(tf_draw_cv2, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "train_ds = train_ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE).shuffle(3000).batch(1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**py_function**的作用：\n",
    "\n",
    "这是因为目前tf.data.Dataset.map函数里头的计算是在计算图模式(Graph mode)下执行，所以里头的Tensors并不会有Eager Execution下才有的numpy属性。\n",
    "\n",
    "解法是使用tf.py_function将我们定义的encode函数包成一个以eager模式执行的TensorFlow Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### from_generator方法\n",
    "\n",
    "gen必须是一个可调用对象，返回支持iter()对象的协议"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen():\n",
    "    for i in itertools.count(1):\n",
    "        yield (i, [1] * i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(object):\n",
    "    def __init__(self, resize_height=64, resize_width=64, batch_size=512, fileList=None, size=256, lw=6):\n",
    "        self.resize_height = resize_height\n",
    "        self.resize_width = resize_width\n",
    "        self.batch_size = batch_size\n",
    "        self.fileList = fileList\n",
    "        self.size = size\n",
    "        self.lw = lw\n",
    "        \n",
    "    def __call__(self):\n",
    "        def _generator(size):\n",
    "            while True:\n",
    "                for filename in np.random.permutation(self.fileList):\n",
    "                    df = pd.read_csv(filename)\n",
    "                    df['drawing'] = df['drawing'].apply(json.loads)\n",
    "                    x = np.zeros((len(df), size, size, 1)).astype(np.float32)\n",
    "                    y = tf.keras.utils.to_categorical(df.y, num_classes=n_labels)\n",
    "                    for x_i, y_i in zip(x, y):\n",
    "                        yield (x_i, y_i)\n",
    "                        \n",
    "        dataset = tf.data.Dataset.from_generator(generator=_generator,\n",
    "                                                output_types=(tf.dtypes.float32, tf.dtypes.int32),\n",
    "                                                output_shapes=((self.resize_height, self.resize_height, 1), (340, )),\n",
    "                                                args=(self.size, self.lw))\n",
    "        dataset = dataset.prefetch(buffer_size=10240)\n",
    "        dataset = dataset.shuffle(buffer_size=10240).batch(self.batch_size)\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MobileNetV2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf.h5\n",
      "17227776/17225924 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.applications.mobilenet.MobileNet(input_shape=None, \n",
    "                                                  alpha=1.0, depth_multiplier=1, dropout=1e-3, include_top=True,\n",
    "                                                 weights='imagenet', input_tensor=None, pooling=None, classes=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline构建\n",
    "* 数据处理：shuffle\n",
    "* 数据读取：from_generator\n",
    "* 建模方法：MobileNetV2\n",
    "* 参数调优：图片大小、batch_size等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 黑白图片\n",
    "\n",
    "def draw_cs2(raw_strokes, size=256, lw=6, time_color=True):\n",
    "    img = np.zeros((BASE_SIZE, BASE_SIZE), np.uint8)\n",
    "    for t, stroke in enumerate(raw_strokes):\n",
    "        for i in range(len(stroke[0]) - 1):\n",
    "            color = 255 - min(t, 10) * 13 if time_color else 255\n",
    "            _ = cv2.line(img, (stroke[0][i], stroke[1][i]),\n",
    "                        (stroke[0][i+1], stroke[1][i+1]), color, lw)\n",
    "    if size != BASE_SIZE:\n",
    "        return cv2.resize(img, (size, size))\n",
    "    else:\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2py37",
   "language": "python",
   "name": "tensorflow2py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
