{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras 训练中使用TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras在回调函数中内置Tensorboard函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0-rc0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.TensorBoard at 0x7f4d5c502630>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.callbacks.TensorBoard(\n",
    "    log_dir='logs',\n",
    "    histogram_freq=0,\n",
    "    write_graph=True,\n",
    "    write_images=False,\n",
    "    update_freq='epoch',\n",
    "    profile_batch=2,\n",
    "    embeddings_freq=0,\n",
    "    embeddings_metadata=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Scalars** 显示了如何将loss与每个时间段改变。还可以使用它来跟踪训练速度，学习率和其他标量值。\n",
    "* **Graphs** 进行了可视化模型。在这种情况下，将现实层的Keras图，确保模型构建\n",
    "* **Distributions**和**Histograms**：显示张量随时间的分布。这对于可视化权重和偏差并验证它们是否以预期的方式变化很有用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0-rc0\n",
      "1.18.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model\n",
    "import numpy as np\n",
    "import datetime\n",
    "print(tf.__version__)\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "tf.config.experimental.set_virtual_device_configuration(\n",
    "    gpus[0],\n",
    "    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2048)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-17bb7203622b>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = np.load(\"mnist.npz\")\n",
    "x_train, y_train, x_test, y_test = mnist['x_train'], mnist['y_train'], mnist['x_test'], mnist['y_test']\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train = x_train[..., tf.newaxis]\n",
    "x_test = x_test[..., tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv1 = Conv2D(32, 3, activation='relu')\n",
    "        self.flatten = Flatten()\n",
    "        self.d1 = Dense(128, activation='relu')\n",
    "        self.d2 = Dense(10, activation='softmax')\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.d1(x)\n",
    "        return self.d2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1374 - accuracy: 0.9591 - val_loss: 0.0587 - val_accuracy: 0.9798\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0420 - accuracy: 0.9868 - val_loss: 0.0503 - val_accuracy: 0.9838\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0221 - accuracy: 0.9929 - val_loss: 0.0589 - val_accuracy: 0.9818\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0135 - accuracy: 0.9954 - val_loss: 0.0594 - val_accuracy: 0.9833\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0087 - accuracy: 0.9971 - val_loss: 0.0824 - val_accuracy: 0.9797\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0072 - accuracy: 0.9975 - val_loss: 0.0661 - val_accuracy: 0.9844\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.0734 - val_accuracy: 0.9819\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.0801 - val_accuracy: 0.9821\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.0710 - val_accuracy: 0.9853\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0039 - accuracy: 0.9986 - val_loss: 0.0927 - val_accuracy: 0.9813\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.0888 - val_accuracy: 0.9846\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0819 - val_accuracy: 0.9849\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.1079 - val_accuracy: 0.9833\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0888 - val_accuracy: 0.9849\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0949 - val_accuracy: 0.9852\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0931 - val_accuracy: 0.9866\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 8.2561e-04 - accuracy: 0.9998 - val_loss: 0.1078 - val_accuracy: 0.9843\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.1150 - val_accuracy: 0.9829\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.1046 - val_accuracy: 0.9847\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.1065 - val_accuracy: 0.9848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4c2cc29048>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyModel()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"keras_logv1\",\n",
    "                                                     histogram_freq=1,\n",
    "                                                     profile_batch=100000000)\n",
    "\n",
    "model.fit(x=x_train,\n",
    "         y=y_train,\n",
    "         epochs=20,\n",
    "         validation_data=(x_test, y_test),\n",
    "         callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
    "\n",
    "# @tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTapea() as tape:\n",
    "        predictions = model(images)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)\n",
    "    \n",
    "def test_step(images, labels):\n",
    "    predictions = model(images)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "    \n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "import os\n",
    "logdir = os.path.join(\"logs/\"+stamp)\n",
    "\n",
    "summary_writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "tf.summary.trace_on(graph=True, profiler=True)\n",
    "EPOCHS=20\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for (x_train, y_train) in train_ds:\n",
    "        train_step(x_train, y_train)\n",
    "        \n",
    "    with summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', train_loss.result(), step=epoch)\n",
    "        tf.summary.scalar('accuracy', train_accuracy,result(), step=epoch)\n",
    "        \n",
    "    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "    print(template.format(epoch + 1,\n",
    "                      train_loss.result(),\n",
    "                      train_accuracy.result() * 100,\n",
    "                      test_loss.result(),\n",
    "                      test_accuracy.result() * 100))\n",
    "    \n",
    "    # Reset metrics every epoch\n",
    "    train_loss.reset_states_states()\n",
    "    test_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "    \n",
    "with summary_writer.as_default():\n",
    "    tf.summary.trace_export(name=\"model_trace\", step=3, profiler_outdir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2py37",
   "language": "python",
   "name": "tensorflow2py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
