{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras 模型保存与加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "x_train = np.random.random((1000, 32))\n",
    "y_train = np.random.randint(10, size=(1000,))\n",
    "x_val = np.random.random((200, 32))\n",
    "y_val = np.random.randint(10, size=(200,))\n",
    "x_test = np.random.random((200, 32))\n",
    "y_test = np.random.randint(10, size=(200,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uncompiled_model():\n",
    "    inputs = tf.keras.Input(shape=(32,), name='digits',dtype=tf.float16)\n",
    "    x = tf.keras.layers.Dense(64, activation='relu', name='dense_1', dtype=tf.float16)(inputs)\n",
    "    x = tf.keras.layers.Dense(64, activation='relu', name='dense_2',dtype=tf.float16)(x)\n",
    "    outputs = tf.keras.layers.Dense(10, name='predictions',dtype=tf.float16)(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "def get_compiled_model():\n",
    "    model = get_uncompiled_model()\n",
    "    model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "                 loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                 metrics=['sparse_categorical_accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_compiled_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 41.3672 - sparse_categorical_accuracy: 0.1060 - val_loss: 27.4319 - val_sparse_categorical_accuracy: 0.1100\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 24.2849 - sparse_categorical_accuracy: 0.1090 - val_loss: 19.0575 - val_sparse_categorical_accuracy: 0.0850\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 19.3415 - sparse_categorical_accuracy: 0.1030 - val_loss: 16.4742 - val_sparse_categorical_accuracy: 0.1050\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 17.3769 - sparse_categorical_accuracy: 0.1050 - val_loss: 14.6544 - val_sparse_categorical_accuracy: 0.1050\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 15.8088 - sparse_categorical_accuracy: 0.1060 - val_loss: 13.6214 - val_sparse_categorical_accuracy: 0.0950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x169e43510>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=32, epochs=5, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "digits (InputLayer)          [(None, 32)]              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 6,922\n",
      "Trainable params: 6,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 方法一 save_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"drrp.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"drrp.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.05852645,  0.01292044, -0.23259905, ..., -0.10551147,\n",
       "        -0.00613356,  0.16358103],\n",
       "       [-0.06289405, -0.1480409 ,  0.36335117, ...,  0.15499479,\n",
       "         0.00501488, -0.12265167],\n",
       "       [ 0.00436173,  0.01297364, -0.13949364, ..., -0.14975196,\n",
       "        -0.16100915,  0.132042  ],\n",
       "       ...,\n",
       "       [-0.18670836, -0.0823878 , -0.2774019 , ..., -0.19423302,\n",
       "        -0.12751162,  0.28515926],\n",
       "       [-0.07826158, -0.36988124, -0.34250683, ...,  0.0766313 ,\n",
       "        -0.21119668,  0.2753719 ],\n",
       "       [ 0.01388641, -0.12932897, -0.04209207, ...,  0.03581356,\n",
       "         0.01053141,  0.1093277 ]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.05852645,  0.01292044, -0.23259905, ..., -0.10551147,\n",
       "        -0.00613356,  0.16358103],\n",
       "       [-0.06289405, -0.1480409 ,  0.36335117, ...,  0.15499479,\n",
       "         0.00501488, -0.12265167],\n",
       "       [ 0.00436173,  0.01297364, -0.13949364, ..., -0.14975196,\n",
       "        -0.16100915,  0.132042  ],\n",
       "       ...,\n",
       "       [-0.18670836, -0.0823878 , -0.2774019 , ..., -0.19423302,\n",
       "        -0.12751162,  0.28515926],\n",
       "       [-0.07826158, -0.36988124, -0.34250683, ...,  0.0766313 ,\n",
       "        -0.21119668,  0.2753719 ],\n",
       "       [ 0.01388641, -0.12932897, -0.04209207, ...,  0.03581356,\n",
       "         0.01053141,  0.1093277 ]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checkpoints\n",
    "model.save_weights('./checkpoints/mannul_checkpoint')\n",
    "model.load_weights('./checkpoints/mannul_checkpoint')\n",
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 方法二 整个模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/fatu/venv/tensorflow2py37/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: path_to_saved_model/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.00409392, -0.00313468, -0.08112855, ..., -0.06384258,\n",
       "        -0.14178936, -0.00161422],\n",
       "       [ 0.12763125, -0.26022148,  0.04546265, ...,  0.06015725,\n",
       "        -0.1318432 , -0.06218194],\n",
       "       [ 0.09995539,  0.03873311,  0.3017472 , ..., -0.32389206,\n",
       "         0.0159488 , -0.07385943],\n",
       "       ...,\n",
       "       [ 0.07943917, -0.26608714,  0.09972487, ...,  0.07722213,\n",
       "        -0.11452483,  0.00932745],\n",
       "       [ 0.06275637,  0.27457577, -0.01840128, ...,  0.10620368,\n",
       "         0.1495491 , -0.12419467],\n",
       "       [ 0.11535957, -0.01981927,  0.0197123 , ...,  0.05708698,\n",
       "         0.04515108, -0.07603381]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save('path_to_saved_model', save_format='tf')\n",
    "\n",
    "new_model = tf.keras.models.load_model('path_to_saved_model')\n",
    "new_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 方法三"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.05852645,  0.01292044, -0.23259905, ..., -0.10551147,\n",
       "        -0.00613356,  0.16358103],\n",
       "       [-0.06289405, -0.1480409 ,  0.36335117, ...,  0.15499479,\n",
       "         0.00501488, -0.12265167],\n",
       "       [ 0.00436173,  0.01297364, -0.13949364, ..., -0.14975196,\n",
       "        -0.16100915,  0.132042  ],\n",
       "       ...,\n",
       "       [-0.18670836, -0.0823878 , -0.2774019 , ..., -0.19423302,\n",
       "        -0.12751162,  0.28515926],\n",
       "       [-0.07826158, -0.36988124, -0.34250683, ...,  0.0766313 ,\n",
       "        -0.21119668,  0.2753719 ],\n",
       "       [ 0.01388641, -0.12932897, -0.04209207, ...,  0.03581356,\n",
       "         0.01053141,  0.1093277 ]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save('path_to_my_model.h5')\n",
    "\n",
    "new_model = tf.keras.models.load_model('path_to_my_model.h5')\n",
    "new_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 方法四"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_saved_model/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model, 'my_saved_model')\n",
    "restored_saved_model = tf.saved_model.load('my_saved_model')\n",
    "f = restored_saved_model.signatures[\"serving_default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': <tf.Tensor: shape=(200, 10), dtype=float32, numpy=\n",
       " array([[ 0.05852645,  0.01292044, -0.23259905, ..., -0.10551147,\n",
       "         -0.00613356,  0.16358103],\n",
       "        [-0.06289405, -0.1480409 ,  0.36335117, ...,  0.15499479,\n",
       "          0.00501488, -0.12265167],\n",
       "        [ 0.00436173,  0.01297364, -0.13949364, ..., -0.14975196,\n",
       "         -0.16100915,  0.132042  ],\n",
       "        ...,\n",
       "        [-0.18670836, -0.0823878 , -0.2774019 , ..., -0.19423302,\n",
       "         -0.12751162,  0.28515926],\n",
       "        [-0.07826155, -0.36988118, -0.3425069 , ...,  0.07663134,\n",
       "         -0.21119669,  0.27537188],\n",
       "        [ 0.01388641, -0.12932895, -0.04209203, ...,  0.03581361,\n",
       "          0.01053139,  0.10932764]], dtype=float32)>}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(digits = tf.constant(x_test.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自定义版本模型保存与加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MyModel, self).__init__(name='my_model')\n",
    "        self.num_classes = num_classes\n",
    "        self.dense_1 = tf.keras.layers.Dense(32, activation='relu')\n",
    "        self.dense_2 = tf.keras.layers.Dense(num_classes)\n",
    "            \n",
    "    @tf.function(input_signature=[tf.TensorSpec([None, 32], tf.float32)])\n",
    "    def call(self, inputs):\n",
    "        x = self.dense_1(inputs)\n",
    "        return self.dense_2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_train = np.random.random((1000, 32))\n",
    "y_train = np.random.randint(10, size=(1000,))\n",
    "x_val = np.random.random((200, 32))\n",
    "y_val = np.random.randint(10, size=(200,))\n",
    "x_test = np.random.random((200, 32))\n",
    "y_test = np.random.randint(10, size=(200,))\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
    "\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "train_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "val_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "batch_size = 64\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_dataset = val_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of epoch 0\n",
      "WARNING:tensorflow:Layer my_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Training loss (for one batch) at step 0: 12.215283393859863\n",
      "Seen so far: 64 samples\n",
      "Training acc over epoch: 0.09799999743700027\n",
      "Validation acc: 0.029999999329447746\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: 11.870205879211426\n",
      "Seen so far: 64 samples\n",
      "Training acc over epoch: 0.10100000351667404\n",
      "Validation acc: 0.019999999552965164\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 0: 11.69017219543457\n",
      "Seen so far: 64 samples\n",
      "Training acc over epoch: 0.10100000351667404\n",
      "Validation acc: 0.02500000037252903\n"
     ]
    }
   ],
   "source": [
    "model = MyModel(num_classes=10)\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    print('Start of epoch %d' % (epoch,))\n",
    "    \n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            \n",
    "            logits = model(x_batch_train, training=True)\n",
    "            \n",
    "            loss_value = loss_fn(y_batch_train, logits)\n",
    "            \n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        \n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        \n",
    "        train_acc_metric(y_batch_train, logits)\n",
    "        \n",
    "        if step % 200 == 0:\n",
    "            print('Training loss (for one batch) at step %s: %s' % (step, float(loss_value)))\n",
    "            print('Seen so far: %s samples' % ((step + 1) * 64))\n",
    "            \n",
    "    train_acc = train_acc_metric.result()\n",
    "    print('Training acc over epoch: %s' % (float(train_acc),))\n",
    "    \n",
    "    train_acc_metric.reset_states()\n",
    "    \n",
    "    for x_batch_val, y_batch_val in val_dataset:\n",
    "        val_logits = model(x_batch_val)\n",
    "        \n",
    "        val_acc_metric(y_batch_val, val_logits)\n",
    "        \n",
    "    val_acc = val_acc_metric.result()\n",
    "    val_acc_metric.reset_states()\n",
    "    print('Validation acc: %s' % (float(val_acc),))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型保存方法一"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.23457022,  0.6700156 ,  0.98961985, ...,  1.0819362 ,\n",
       "         0.2749272 ,  0.8553397 ],\n",
       "       [ 0.46010363,  0.5857373 ,  0.9385505 , ...,  0.7562412 ,\n",
       "         0.6000906 ,  0.47855237],\n",
       "       [ 0.35790527,  0.45883706,  1.5235121 , ...,  0.49148226,\n",
       "        -0.15018994,  1.312606  ],\n",
       "       ...,\n",
       "       [ 0.7966254 ,  0.7490465 ,  0.97471374, ...,  0.5026726 ,\n",
       "         0.04536883,  0.6334813 ],\n",
       "       [ 0.11808767,  0.6573901 ,  0.71505857, ...,  0.7634459 ,\n",
       "         0.30052808,  0.32086703],\n",
       "       [ 0.10565991,  0.4186309 ,  0.86704206, ...,  0.8332339 ,\n",
       "         0.34078637,  0.52047175]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_weights(\"drrp.h5\")\n",
    "model.load_weights(\"drrp.h5\")\n",
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.23457022,  0.6700156 ,  0.98961985, ...,  1.0819362 ,\n",
       "         0.2749272 ,  0.8553397 ],\n",
       "       [ 0.46010363,  0.5857373 ,  0.9385505 , ...,  0.7562412 ,\n",
       "         0.6000906 ,  0.47855237],\n",
       "       [ 0.35790527,  0.45883706,  1.5235121 , ...,  0.49148226,\n",
       "        -0.15018994,  1.312606  ],\n",
       "       ...,\n",
       "       [ 0.7966254 ,  0.7490465 ,  0.97471374, ...,  0.5026726 ,\n",
       "         0.04536883,  0.6334813 ],\n",
       "       [ 0.11808767,  0.6573901 ,  0.71505857, ...,  0.7634459 ,\n",
       "         0.30052808,  0.32086703],\n",
       "       [ 0.10565991,  0.4186309 ,  0.86704206, ...,  0.8332339 ,\n",
       "         0.34078637,  0.52047175]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checkpoints\n",
    "model.save_weights('./checkpoints/mannul_checkpoint')\n",
    "model.load_weights('./checkpoints/mannul_checkpoint')\n",
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型保存方法二"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: path_to_my_model/assets\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.23457022,  0.6700156 ,  0.98961985, ...,  1.0819362 ,\n",
       "         0.2749272 ,  0.8553397 ],\n",
       "       [ 0.46010363,  0.5857373 ,  0.9385505 , ...,  0.7562412 ,\n",
       "         0.6000906 ,  0.47855237],\n",
       "       [ 0.35790527,  0.45883706,  1.5235121 , ...,  0.49148226,\n",
       "        -0.15018994,  1.312606  ],\n",
       "       ...,\n",
       "       [ 0.7966254 ,  0.7490465 ,  0.97471374, ...,  0.5026726 ,\n",
       "         0.04536883,  0.6334813 ],\n",
       "       [ 0.11808767,  0.6573901 ,  0.71505857, ...,  0.7634459 ,\n",
       "         0.30052808,  0.32086703],\n",
       "       [ 0.10565991,  0.4186309 ,  0.86704206, ...,  0.8332339 ,\n",
       "         0.34078637,  0.52047175]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 不能保存H5\n",
    "model.save('path_to_my_model')\n",
    "\n",
    "new_model = tf.keras.models.load_model('path_to_my_model')\n",
    "new_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 方法四"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_saved_model/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model, 'my_saved_model')\n",
    "restored_saved_model = tf.saved_model.load('my_saved_model')\n",
    "f = restored_saved_model.signatures[\"serving_default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_1': <tf.Tensor: shape=(200, 10), dtype=float32, numpy=\n",
       " array([[ 0.23457022,  0.6700156 ,  0.98961985, ...,  1.0819362 ,\n",
       "          0.2749272 ,  0.8553397 ],\n",
       "        [ 0.46010363,  0.5857373 ,  0.9385505 , ...,  0.7562412 ,\n",
       "          0.6000906 ,  0.47855237],\n",
       "        [ 0.35790527,  0.45883706,  1.5235121 , ...,  0.49148226,\n",
       "         -0.15018994,  1.312606  ],\n",
       "        ...,\n",
       "        [ 0.7966254 ,  0.7490465 ,  0.97471374, ...,  0.5026726 ,\n",
       "          0.04536883,  0.6334813 ],\n",
       "        [ 0.11808767,  0.6573901 ,  0.71505857, ...,  0.7634459 ,\n",
       "          0.30052808,  0.32086703],\n",
       "        [ 0.10565991,  0.4186309 ,  0.86704206, ...,  0.8332339 ,\n",
       "          0.34078637,  0.52047175]], dtype=float32)>}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(args_0 = tf.constant(x_test.tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2py37",
   "language": "python",
   "name": "tensorflow2py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
